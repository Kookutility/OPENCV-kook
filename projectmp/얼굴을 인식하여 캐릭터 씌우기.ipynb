{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007028a3",
   "metadata": {},
   "source": [
    "# 프로젝트: 얼굴을 인식하여 캐릭터 씌우기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63290f2",
   "metadata": {},
   "source": [
    "## Face Detection vs Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a51aad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The path does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 웹캠, 영상 파일의 경우 이것을 사용하세요.:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_face_detection\u001b[38;5;241m.\u001b[39mFaceDetection(\n\u001b[0;32m      9\u001b[0m     model_selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m face_detection:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m     11\u001b[0m         success, image \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solutions\\face_detection.py:82\u001b[0m, in \u001b[0;36mFaceDetection.__init__\u001b[1;34m(self, min_detection_confidence, model_selection)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a MediaPipe Face Detection object.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    https://solutions.mediapipe.dev/face_detection#model_selection.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m binary_graph_path \u001b[38;5;241m=\u001b[39m _FULL_RANGE_GRAPH_FILE_PATH \u001b[38;5;28;01mif\u001b[39;00m model_selection \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m _SHORT_RANGE_GRAPH_FILE_PATH\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     83\u001b[0m     binary_graph_path\u001b[38;5;241m=\u001b[39mbinary_graph_path,\n\u001b[0;32m     84\u001b[0m     graph_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_graph_options(\n\u001b[0;32m     85\u001b[0m         face_detection_pb2\u001b[38;5;241m.\u001b[39mFaceDetectionOptions(), {\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_score_thresh\u001b[39m\u001b[38;5;124m'\u001b[39m: min_detection_confidence,\n\u001b[0;32m     87\u001b[0m         }),\n\u001b[0;32m     88\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetections\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solution_base.py:264\u001b[0m, in \u001b[0;36mSolutionBase.__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    262\u001b[0m validated_graph \u001b[38;5;241m=\u001b[39m validated_graph_config\u001b[38;5;241m.\u001b[39mValidatedGraphConfig()\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_graph_path:\n\u001b[1;32m--> 264\u001b[0m   validated_graph\u001b[38;5;241m.\u001b[39minitialize(\n\u001b[0;32m    265\u001b[0m       binary_graph_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, binary_graph_path))\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m   validated_graph\u001b[38;5;241m.\u001b[39minitialize(graph_config\u001b[38;5;241m=\u001b[39mgraph_config)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The path does not exist."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠, 영상 파일의 경우 이것을 사용하세요.:\n",
    "cap = cv2.VideoCapture('face_video.mp4')\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "            \n",
    "        # 보기 편하기 위해 이미지를 좌우를 반전하고, BGR 이미지를 RGB로 변환합니다.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # 성능을 향상시키려면 이미지를 작성 여부를 False으로 설정하세요.\n",
    "        image.flags.writeable = False\n",
    "        results = face_detection.process(image)\n",
    "\n",
    "        # 영상에 얼굴 감지 주석 그리기 기본값 : True.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)\n",
    "        cv2.imshow('MediaPipe Face Detection', image)\n",
    "        if cv2.waitKey(1) == ord ('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f61ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed81bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
